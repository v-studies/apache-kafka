- whimsical : https://whimsical.com/VAy2zRn5aM98VnFh585pY2
# 3.1. 카프카 브로커 / 클러스터 / 주키퍼
![[Pasted image 20250906183411.png]]
- 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 분산 저장 시 발생 할 수 있는 장애를 최소화 해주는 애플리케이션
## 3.1.1. 데이터 저장, 전송
- 카프카는 데이터를 파일 시스템에 저장함
	- 파일의 IO 때문에 속도가 느려지는 문제를 페이지 캐시로 해결
## 3.1.2. 데이터 복제(replication), 싱크(synchronization)
![[Pasted image 20250906185256.png]]
- 클러스터로 묶인 브로커 중 일부에 장애가 발생 하여도 데이터를 유실하지 않고 안전하게 사용하기 위함
- 데이터 복제는 파티션 단위로 이루어짐
	- 복제 개수 최솟값은 1 (복제 없음)
	- 최대 값 : 브로커 갯수
- 복제 된 파티션
	- 리더와 팔로워로 구성됨
		- 리더 : 프로듀서 또는 컨슈머와 직접 통신함
		- 팔로워 : 복제 데이터를 가지고 있음
			- 복제 조건: 리더 파티션의 오프셋과 자신의 오프셋을 비교, 다른경우 복제(replication) 수행
	- 장애 발생 시 팔로워 파티션중 하나가 리더 파티션 지위를 넘겨 받음
		- ![[Pasted image 20250906191358.png]]
## 3.1.3. 컨트롤러(Controller)
![[Pasted image 20250906192411.png]]
- 다수의 브로커 중 한 대가 컨트롤러 역할을 수행
- 컨트롤러는 다른 브로커 상태를 체크
	- 브로커가 클러스터에서 빠지는 경우 브로커에 존재하는 파티션 재분배
	- 브로커의 상태가 비정상이라면 빠르게 클러스터에서 제거
- 만약 컨트롤러 브로커에 장애 발생 시
	- 다른 브로커가 컨트롤러 역할 수행
## 3.1.4. 데이터 삭제
- 삭제 조건
	- 카프카는 MQ 와 다르게 컨슈머가 데이터를 가져가도 토픽의 데이터는 삭제되지 않음
	- 컨슈머, 프로듀서가 삭제를 요청 할 수 없음
	- 브로커 만 데이터 삭제 가능
- 삭제 방식
	- 파일 단위로 삭제 (로그 세그먼트(log segment) 단위)
		- 특정 데이터 선별하여 지울 수 없음
	- 세그먼트는 데이터가 쌓이는 동안 열려있음
		- log.segment.bytes or log.segment.ms 옵션 값이 되면 닫힘
			- 기본값 1GB
- 삭제 대신 압축 가능
	- 카프카는 메시지 키 기준으로 압축하는 정책을 가져갈 수 있음
## 3.1.5. 컨슈머 오프셋 저장
- 레코드를 가져가는 근거
	- 컨슈머 그룹은 토픽 데이터의 처리를 기록하며 이것을 커밋한다
		- 이 커밋은 `__consumer_offsets` 토픽에 저장된다
		- 저장되는 내용 : 
			- 어떤 파티션으로 부터 데이터를 가져갔는가?
			- 어느 레코드까지 가져갔는가?
## 3.1.6. 코디네이터(coordinator)
![[Pasted image 20250906202925.png]]
- 클러스터의 다수 브로커 중 한 대는 코디네이터 역할 수행
- 리밸런스
	- 컨슈머 그룹의 상태를 체크
	- 파티션과 컨슈머를 매칭 & 분배
	- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상동작 하는 컨슈머로 할당
	- 리밸런싱 중 파티션의 소유권을 컨슈머로 재할당 하는 과정에서 컨슈머 그룹의 컨슈머들은 토픽 데이터를 읽을 수 없다.
## 3.1.7. 주키퍼의 역할
![[Pasted image 20250906202739.png]]
- 주키퍼는 카프카의 메타 데이터를 관리
- 자세한 정보 참고 : https://zookeeper.apache.org/doc/current/zookeeperStarted.html
# 3.2. 토픽과 파티션
## 3.2.1. 개념
![[Pasted image 20250906205412.png]]
- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위
- 파티션에는 프로듀서가 보낸 데이터들이 저장됨 -> 이걸 레코드라고 함
	- ![[Pasted image 20250906211109.png]]
		- 위 상황에서 처리량을 늘리려면 스케일 아웃하면 됨
			- ![[Pasted image 20250906211256.png]]
- 파티션은 큐(Queue) 와 비슷한 구조라고 이해하면 쉬움
	- FIFO(First in first out)
## 3.2.2. 토픽 이름 템플릿과 예시
1. **허용 문자**
    - 알파벳 소문자/대문자 (a-z, A-Z)
    - 숫자 (0-9)
    - 마침표(`.`), 밑줄(`_`), 대시(`-`)
2. **금지 문자**
    - 공백(space) 불가
    - 슬래시(`/`), 역슬래시(`\`), 콜론(`:`), 물음표(`?`), 별표(`*`) 등 특수문자 불가
    - ASCII 외 문자(한글, 일본어, 이모지 등) 사용 불가
3. **길이 제한**
    - 최소 1자 이상
    - 최대 249자까지 가능 (250자 이상이면 InvalidTopicException 발생)
4. **예약된 이름 제약**
    - "." (마침표 하나) 또는 ".." (마침표 두 개)로만 된 이름은 불가
    - "`__consumer_offsets`" 토픽은 Kafka 내부에서 사용하는 예약 토픽이므로 직접 생성 불가
5. **권장사항 (Best Practice)**
    - 토픽 이름은 의미 있는 prefix 사용 → 예: prod.orders.created
    - 환경 구분(dev_, stg_, prod_) 붙이는 방식 권장
    - 너무 긴 이름은 관리 어려움 → 50자 이내 권장
- 토픽 이름은 모호하게 작성하면 유지보수 어려움
- 아래의 템플릿 제시
> [!note 토픽 작명의 템플릿과 예시]
> - `<환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>`
>     - 예시: `prod.marking-team.sms-platform.json`
> - `<프로젝트-명>.<서비스-명>.<환경>.<이벤트-명>`
>     - 예시: `commerce.paymemt.prod.notification`
> - `<환경>.<서비스-명>.<JIRA-번호>.<메시지-타입>`
>     - 예시: `dev.email-sender.jira-1234.email-vo-custom`
> - `<카프카-클러스터-명>.<환경>.<서비스-명>.<메시지-타입>`
>     - 예시: `aws-kafka.live.marketing-platform.json`
# 3.3. 레코드
- 레코드의 구성
	- 타임스탬프
		- 아무런 행위를 하지 않으면 레코드가 생성된 시점의 유닉스 타임이 설정됨
		- 프로듀서에 의해 값이 설정될 수 있음
		- 토픽의 설정에 따라 브로커에 적재된 시간으로 설정될 수 있음
	- 메시지 키
		- 메시지 값을 순서대로 처리하거나, 값의 종류를 나타내기위해 사용
		- 메시지 키의 해시값을 토대로 파티션을 지정함
			- 동일한 메시지 키 라면 동일 파티션에 들어감
		- 사용하지 않으려면 프로듀서에서 키를 선언하지 않으면 됨
			- null 로 설정됨
			- 프로듀서 기본 설정 파티셔너에 따라 파티션에 분배
	- 메시지 값
		- 실질적으로 처리 될 데이터 적재
		- 직렬화 이슈 존재
			- 프로듀서와 컨슈머는 반드시 같은 직렬화/역직렬화 함수를 거쳐야 함
			- StringSerializer 로 직렬화 된 데이터를 IntegerDeseriazlier 로 역직렬화 하면 비정상 데이터 확인 가능
	- 오프셋
		- 0 이상의 숫자로 이루어짐
		- 직접 지정할 수 없음
			- 브로커에 저장될 때 이전에 전송된 레코드의 오프셋+1 값으로 생성됨
		- 카프카 컨슈머가 데이터를 가져갈 때 사용
		- 사용 시 장점
			- 컨슈머그룹이 파티션의 데이터를 어디까지 가져갔는지 명확히 지정 가능
	- 헤더
		- 레코드의 추가적인 정보를 담는 메타데이터 저장소
		- 키/값 형태로 데이터 추가하여 레코드의 속성(스키마 버전 등)을 저장하여 컨슈머에서 참조 가능
- 레코드의 특징
	- 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장됨
	- 브로커에 한 번 적재 된 레코드는 수정할 수 없음
	- 삭제도 불가능하지만 리텐션 기간 혹은 용량에 따라서만 삭제됨
# 3.4. 카프카 클라이언트 라이브러리
- 기능
	- 카프카 클러스터에 명령
	- 카프카 데이터 송수신
	- 프로듀서, 컨슈머, 어드민 클라이언트
## 3.4.1. 프로듀서 api
- 프로듀서(Producer)는 Kafka 토픽에 메시지를 발행(Publish)하는 역할
- 메시지는 레코드(Record) 단위로 전송 → (topic, key, value, headers, timestamp) 구조
- 파티션(partition)은 key 또는 파티셔너(Partitioner)에 의해 결정됨
### 3.4.1.1. 프로듀서 api > 주요 클래스 
- KafkaProducer<K, V>
	- 데이터를 전송하는 핵심 클래스
	- 직렬화 필요 → key.serializer, value.serializer 설정 필수
- ProducerRecord<K, V>
	- 전송할 메시지를 표현하는 객체
	- 필드
		- topic (필수)
		- partition (선택)
		- key (선택)
		- value (필수)
		- headers (선택)
		- timestamp (선택)
- 주요 메서드
	- send()
		- 비동기 전송
		- RecordMetadata 로 토픽, 파티션, 오프셋 정보 반환
		- Callback 등록 가능 (성공/실패 처리)
	- flush()
		- 버퍼에 쌓여 있는 메시지를 즉시 전송
	- close()
		- 프로듀서 종료, 리소스 해제
### 3.4.1.2. 프로듀서 api > 중요 개념
![[Pasted image 20250906222446.png]]
- 프로듀서는 카프카 브로커로 데이터를 전송 할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다
- 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 데이터를 전송함
send 메서드 호출 시
1. send 메서드 호출. 이 때 레코드 정보를 넘긴다.
2. ProducerRecord 는 파티셔너(Partitioner) 에 의해 토픽의 어느 파티션으로 전송 될 것인지 정해짐
	- KafkaProducer 인스턴스를 생성 할 때 파티셔너를 따로 설정하지 않으면 기본값인 DefaultPartitioner 로 설정되어 파티션이 정해짐
3. 파티셔너(partitioner) 에 의해 구분된 레코드는 데이터를 전송하기 전 어큐뮬레이터(Accumulator) 에 데이터를 버퍼로 쌓아놓고 발송함
	- 버퍼로 쌓인 데이터는 배치로 묶어서 전송
	- 카프카 프로듀서의 처리량 향상
4. Sender 가 Kafka 클러스터로 전송
	- 참고: `example-kafka-project/src/main/java/example/kafka/producer`
파티셔너(partitioner) 종류
- RoundRobinPartitioner
	- ProducerRecord 가 들어오는대로 파티션을 순회하며 전송
	- 버퍼 등 묶어보내는 빈도 감소
		- 전송 요청 빈도 증가
- UniformStickyPartitioner (프로듀서 api 2.5.0 에서 기본 파티셔너)
	- RoundRobinPartitioner 의 단점 개선 구현체
	- 어큐뮬레이터 적용 버전
		- 데이터가 배치로 모두 묶일 때 까지 기다렸다 전송
- 커스텀 파티셔너(Paritioner)
	- 파티셔너 인터페이스를 이용하여 구현
	- 참고: ![[CustomPartitioner.java]]
둘 다 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 데이터를 전송함
## 3.4.2. 컨슈머 api
- 참고: ![[SimpleConsumer.java]]
### 3.4.2.1. 중요 개념
- 컨슈머 운영하는 방법은 크게 2가지
	- 컨슈머 그룹 운영
		- ![[Pasted image 20250907121250.png]]
	- 토픽의 특정 파티션만 구독하는 컨슈머 운영
		- ![[Pasted image 20250907121000.png]]
			- 개별 컨슈머들이 여러 파티션의 데이터를 동시에 읽을 수 있다
			- 브로커는 모든 개별 컨슈머에 데이터를 전달한다
#### 3.4.2.1.1. 컨슈머 그룹 운영
![[Pasted image 20250907122112.png]]
- 컨슈머를 각 컨슈머 그룹으로부터 격리 된 환경에서 운영
- 파티션(n) : 컨슈머(1)
	- 컨슈머 그룹에서 1개의 파티션은 최대 1개의 컨슈머에 할당 가능
	- 컨슈머 그룹에서 1개의 컨슈머는 여러개의 파티션에 할당 될 수 있음
- 따라서 컨슈머 그룹의 컨슈머 수는 토픽 파티션의 개수와 같거나 보다 작아야 함
> [!note 컨슈머 갯수가 많을 경우 생기는 문제]
> ![[Pasted image 20250907122432.png]]
> - 컨슈머 2는 파티션이 할당되지 않아서, 스레드만 차지할 수 있음
- 컨슈머 그룹은 다른 컨슈머 그룹과 격리됨
	- 각기 다른 역할을 하는 컨슈머 그룹 끼리 영향을 받지 않게 할 수 있음
#### 3.4.2.1.2. 동기 로직 애플리케이션과 비교
![[Pasted image 20250907130847.png]]
- 만약 위 로직을 동기 방식으로 처리한다면
	- 엘라스틱서치, 하둡 둘 중 하나에 장애가 발생하면 적재가 불가능 할 수 있음
- 카프카로 처리 한다면
	- 오프셋을 토대로 각 컨슈머 그룹이 가져간 마지막 데이터를  확인 가능
	- 장애 복구가 가능함
- 리밸런싱 장애 복구
	- ![[Pasted image 20250907131909.png]]
- 컨슈머 그룹으로 단일실패지점 방어
	- ![[Pasted image 20250907132745.png]]
#### 3.4.2.1.3. 오프셋 커밋
![[Pasted image 20250907142529.png]]
- 컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 커밋을 통해 기록함
	- 브로커 내부에 `__consumer_offsets` 토픽에 기록 함
	- 오프셋 커밋이 기록되지 못했다면 데이터 처리의 중복이 발생 할 수 있음
- 오프셋 커밋 개념
	- ![[Pasted image 20250907144518.png]]
- 오프셋 커밋 방법
	- 명시적 커밋
		- `commitSync()` 메서드 (참조: ![[ManualCommitConsumer.java]])
			- `poll()` 메서드를 통해 반환된 레코드의 가장 마지막 오프셋 기준으로 커밋 수행
				- 따라서 모든 처리 로직이 끝난 이후 호출 추천
			- 커밋 정상 처리 여부를 리턴하므로 동기 방식
		- `commitAsync()` 메서드 (참조: ![[AsyncCommitConsumer.java]])
			- 비동기 커밋은 커밋 요청이 실패했을 때 현재 처리중인 데이터의 순서를 보장하지 않음
				- 따라서 데이터 중복 처리가 발생 할 수 있음
	- 비명시적 커밋 (참조: ![[SimpleConsumer.java]])
		- `auto.commit.interval.ms`
			- poll 메서드의 시간 기준 자동 커밋
			- 커밋 시간 직전에 리밸런싱, 컨슈머 강제종료 발생 시 데이터 유실 가능성
### 3.4.2.2. 컨슈머 내부 구조
![[Pasted image 20250907151215.png]]
### 3.4.2.3. 리밸런스 리스너를 가진 컨슈머
- 컨슈머가 추가/제거 되면 파티션을 컨슈머에 재할당하는 과정인 리밸런스 발생함
	- poll() 메서드 통해 받은 데이터 처리 전 리밸런스 발생 시 데이터 중복 처리 가능성
		- 커밋되지 않았기 때문
	- 중복 처리를 막기 위해서는 처리한 데이터 기준으로 커밋 시도해야함
		- 리밸런스 감지를 위해 아래의 인터페이스 지원
			- `ConsumerRebalanceListener`
				- 메서드: `onPartitionAssigned()`
					- 리밸런스 끝난 뒤 파티션 할당 완료되면 호출됨
				- 메서드: `onPartitionRevoked()`
					- 리밸런스 시작 직전 호출됨
		- 마지막 처리 레코드를 기준으로 커밋은 `onPartitionRevoked()` 메서드 사용
#### 파티션 직접 할당
- 컨슈머에 파티션 직접 할당 가능
	- assign() 메서드 사용
		- subscribe() 는 자동할당
#### 컨슈머에 할당된 파티션 확인
```java
try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {  
	consumer.subscribe(Collections.singletonList(TOPIC_NAME));
	Set<TopicPartition> assginedTopicPartition = consumer.assignment();
} catch (Exception e) {
	...
}
```
#### 컨슈머의 안전한 종료
- 정상종료 되지 않으면 타임아웃 발생까지 컨슈머 그룹에 남음
	- 파티션의 데이터는 소모되지 못하고 컨슈머 랙이 늘어나게 됨
	- 컨슈머 랙이 늘어나면 데이터 처리 지연 발생
- 정상종료 지원 클래스
	- `KafkaConsumer.wakeup()`
		- 해당 메서드 실행 이후 poll() 호출 시 WakeupException 예외 발생
		- 예외 수신 시 자원 해제
		- 마지막에 close 호출하여 명시적 종료
## 3.4.3. ADMIN api
- 카프카 클라이언트는 AdminClient 클래스를 제공함
	- 클러스터 옵션 확인 가능
	- 웹 대시보드를 통해 ACL 이 적용된 클러스터의 리소스 접근 권한 규칙 추가 가능
	- 토픽 파티션 데이터량 모니터링 및 파티션 제어
# 3.5. 카프카 스트림즈
![[Pasted image 20250907194348.png]]
토픽에 적재된 데이터를 상태 기반(Stateful) 또는 무상태(Stateless) 로 실시간 변환하여 적재하는 라이브러리
- 안정성이 뛰어남
	- 카프카 브로커의 장애가 발생해도 "정확히 한번" 할 수 있도록 장애 허용 시스템을 가지고 있다
![[Pasted image 20250907200500.png]]
- 스트림즈 애플리케이션은 스레드를 1개이상 생성 가능
	- 스레드는 1개이상의 태스크를 가진다
		- 태스크
			- 데이터 처리 최소단위
			- 만약 3개의 파티션으로 이루어진 토픽을 처리하는 애플리케이션을 실행하면 내부에 3개의 태스크가 생김
## 3.5.0.1. 개념
![[Pasted image 20250907210605.png]]
- 토폴로지(topology)
	- 2개 이상의 노드들과 선으로 이루어진 집합
- 프로세서(Processor)
	- 토폴로지를 이루는 노드
- 스트림(Stream)
	- 노드와 노드를 이은 선
## 3.5.0.2. 카프카 스트림즈 종류
![[Pasted image 20250907211700.png]]
- 프로세서 종류
	- 소스 프로세서
		- 데이터 처리를 위해 최초로 선언해야 하는 노드
	- 스트림 프로세서
		- 다른 프로세서가 반환한 데이터 처리
		- 변환, 분기 처리
	- 싱크 프로세서
		- 데이터를 특정 카프카 토픽에 적재
## 3.5.0.3. 스트림즈 구현 방식
- 스트림즈 DSL
	- 메시지 값을 기반으로 토픽 분기 처리
	- 지난 10분간 들어온 데이터의 개수 집계
	- 토픽과 다른 토픽의 결합으로 새로운 데이터 생성
- 프로세서 API
	- 메시지 값의 종류에 따라 토픽을 가변적으로 전송
	- 일정한 시간 간격으로 데이터 처리
# 3.5.1. 스트림즈 DSL
- 레코드의 흐름을 추상화 한 3가지 개념 존재
	- KStream
	- KTable
	- GlobalKTable
## 3.5.1.1. KStream
- 키와 메시지 값으로 구성되어 있음

