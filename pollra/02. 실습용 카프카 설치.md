- aws 인스턴스 생성, pem 등록, ssh 연결 후
## java 설치
```shell
sudo yum list | grep 'java'
```
아래는 결과
```shell
janino-javadoc.noarch                                             3.1.7-1.amzn2023.0.2                        amazonlinux
jansi-javadoc.x86_64                                              2.4.0-3.amzn2023.0.3                        amazonlinux
jansi-native-javadoc.noarch                                       1.8-9.amzn2023.0.2                          amazonlinux
jansi1-javadoc.noarch                                             1.18-11.amzn2023.0.1                        amazonlinux
java-1.8.0-amazon-corretto.x86_64                                 1:1.8.0_462.b08-1.amzn2023                  amazonlinux
java-1.8.0-amazon-corretto-devel.x86_64                           1:1.8.0_462.b08-1.amzn2023                  amazonlinux
java-11-amazon-corretto.x86_64                                    1:11.0.28+6-1.amzn2023                      amazonlinux
java-11-amazon-corretto-devel.x86_64                              1:11.0.28+6-1.amzn2023                      amazonlinux
java-11-amazon-corretto-headless.x86_64                           1:11.0.28+6-1.amzn2023                      amazonlinux
java-11-amazon-corretto-javadoc.x86_64                            1:11.0.28+6-1.amzn2023                      amazonlinux
java-11-amazon-corretto-jmods.x86_64                              1:11.0.28+6-1.amzn2023                      amazonlinux
java-17-amazon-corretto.x86_64                                    1:17.0.16+8-1.amzn2023.1                    amazonlinux
java-17-amazon-corretto-debugsymbols.x86_64                       1:17.0.16+8-1.amzn2023.1                    amazonlinux
```

```shell
sudo yum install -y java-1.8.0-amazon-corretto.x86_64
```

## 주키퍼 & 카프카 브로커 실행
### 설치
```shell
wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz
```

```shell
tar xvf kafka_2.12-2.5.0.tgz
```
- 카프카 패키지의 힙 메모리는 아래와 같은 리소스 사용량을 가지고 있다
	- 카프카 브로커 1G
	- 주키퍼 512MB
- 카프카 브로커와 주키퍼를 기본 설정과 함께 사용하면 1.5G 필요
- 아래의 명령어로 메모리 지정 가능
```shell
export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
echo $KAFKA_HEAP_OPTS

```
- 위 명령어를 통해 지정된 내용은 아래의 소스파일에서 확인 가능
```shell
cat {카프카_설치_경로}/bin/kafka-server-start.sh
```
아래는 예시
![[스크린샷 2025-08-25 23.18.39.png]]
config 폴더 안에서 여러 옵션 조정 가능
![[스크린샷 2025-08-26 19.09.49.png]]
```
$ bin/kafka-topics.sh \
  --create \
  --bootstrap-server my-kafka:9092 \
  --partitions 3 \ -- 파티션 갯수
  --replication-factor 1 \ -- 토픽의 파티션 복제 개수. (1: 복제안함. 2: 1개복제, )
  --config retention.ms=172800000 \ -- 추가적인 설정 기능
  --topic hello.kafka.2
Created topic hello.kafka.2
```
- config : 
	- retention.ms : 토픽의 데이터를 유지하는 기간. 위의 값은 2일 이후 삭제
	- 나머지는 검색
> [!note 토픽 생성 시 zookeeper 사용 안하는 이유]
> - 카프카 2.1을 포함한 이전 버전에서는 주키퍼와 직접 통신함
> - 카프카 2.2 이후로는 카프카를 통해 명령 실행 가능.
>     - 주키퍼와 직접 통신 하는건 시스템 복잡도를 높였기 때문
> 위의 이유로 bootstrap-server 명령어 사용

## 토픽 상세 조회
```
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2
```
- 이미 생성된 토픽 상태를 --describe 옵션 사용하여 확인 가능.
- 확인 할 수 있는 정보
	- 파티션의 갯수
	- 복제된 파티션이 위치한 브로커 번호
	- 토픽을 구성하는 설정
### 토픽 옵션 수정
- 이미 생성 된 토픽의 옵션을 수정하기 위해 아래의 두개 명령어 사용 가능
	- kafka-topics.sh
		- 파티션 개수 변경
	- kafka-configs.sh
		- 리텐션(삭제 정책) 기간을 변경
## kafka-console-producer.sh
- 생성된 토픽에 데이터를 넣을 수 있는 명령어
- 토픽에 넣는 데이터는 레코드라고 함
	- key : value 로 이루어짐
```shell
bin/kafka-console-producer --bootstrap-server my-kafka:9092 \
 --topic hello.kafka
>hello
>kafka
>0
>1
>2
>3
>4
>5
```
docker 명령어
```
$ docker exec -it pollra-kafka-1 bash
$ kafka-topics --create \
>   --topic test-topic \
>   --bootstrap-server localhost:9092 \
>   --partitions 1 \
>   --replication-factor 1
Created topic test-topic.
$ kafka-console-producer --topic test-topic --bootstrap-server localhost:9092
>hello
>kafka
>0
>1
>2
>3
>4
>5
>
```
#### 메시지 키를 가지는 레코드 전송
```shell
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 |
 --topic hello.kafka \
 --property "parse.key=true" \
 --property "key.separator=:"
>key1:no1
>key2:no2
>key3:no3
```
docker 명령어
```shell
$ kafka-console-producer --bootstrap-server localhost:9092 \
 --topic test-topic \
 --property "parse.key=true" \ <- 메시지 키 설정
 --property "key.separator=:" <- 키와 값 구분자
>key1:no1
>key2:no2
>key3:no3
```
- 만일 키/값 구분자를 셋팅하지 않으면 탭 문자(\t) 로 자동 설정 됨
- key.separator 로 선언 된 구분자를 넣지 않고 엔터 누르면 KafkaException 발생
## kafka-console-consumer.sh
```shell
$ kafka-console-consumer \
  --bootstrap-server localhost:9092 \ <- [필수]카프카 클러스터 정보
  --topic test-topic \ <- [필수]토픽 정보
  --property print.key=true \ <- [옵션] 설정하면 메시지 키 확인 가능
  --property key.separator="-" \ <- [옵션] 키 구분자. 키-값 형태로 출력
  --group hello-group
  --from-beginning <- [옵션]토픽에 저장된 가장 처음 데이터부터 출력
```
- 이렇게 하면 입력 순서와 달라지게 됨
	- 파티션 개념 때문에 생기는 현상
		- consumer 명령을 통해 가져가면 모두 같은 중요도로 데이터 수신
	- 순서 보장하고 싶으면?
		- 파티션 1개로 구성된 토픽 만들면 됨
```shell
$ kafka-console-consumer --bootstrap-server localhost:9092 --topic test-topic --property print.key=true --property key.separator="-" --group hello-group --from-beginning
null-hello
null-kafka
null-0
null-1
null-2
null-3
null-4
null-5
key1-no1
key2-no2
^CProcessed a total of 10 messages
```
## kafka-consumer-groups.sh
- 생성 된 컨슈머 그룹 리스트를 확인 가능
- 생성은 위의 kafka-console-consumer 명령어 동작 시 그룹 설정을 입력하면 생성됨.
```shell
$ kafka-consumer-groups --bootstrap-server localhost:9092 --list
hello-group
```
- --list
	- 컨슈머 그룹의 리스트 확인
```shell
$ kafka-consumer-groups --bootstrap-server localhost:9092 \
> --group hello-group \ <- 그룹 정보 확인
> --describe <- 상세 내용 확인 명령어

Consumer group 'hello-group' has no active members.

GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
hello-group     test-topic      0          10              10              0               -               -               -
```
![[스크린샷 2025-09-01 23.08.20.png]]
- GROUP : 조회한 컨슈머 그룹이 마지막으로 커밋한 토픽과 파티션
- TOPIC : 조회한 컨슈머 그룹이 마지막으로 커밋한 토픽과 파티션
- PARTITION : 조회한 컨슈머 그룹이 마지막으로 커밋한 토픽과 파티션
- 조회한 컨슈머 그룹이 마지막으로 커밋한 토픽과 파티션![[스크린샷 2025-09-01 23.10.29.png]]
	- GROUP
	- TOPIC
	- PARTITION
- 가장 최신의 오프셋이 몇 번 인지 나타냄
  ![[스크린샷 2025-09-01 23.10.47.png]]
	- 데이터가 파티션에 들어올 때 마다 1씩 증가.
	- 최신 오프셋은 10으로서 10개 데이터 들어감
- ![[스크린샷 2025-09-01 23.12.45.png]]
  어느 오프셋까지 커밋 했는지 알 수 있음
	- CURRENT-OFFSET 은 이 값 보다 같거나 작음.
- ![[스크린샷 2025-09-01 23.13.36.png]]
  해당 컨슈머 그룹이 토픽의 파티션에 있는 데이터를 가져가는 데에 얼마나 지연이 발생하는지 타나내는 지표.
	- 컨슈머 그룹이 커밋한 오프셋과 해당 파티션의 가장 최신 오프셋 간의 차이
	- hello-group 은 0번 파티션의 가장 최신 오프셋과 커밋한 오프셋이 같으므로 이 값이 0
- ![[스크린샷 2025-09-01 23.15.47.png]]
	- CONSUMER-ID
		- 컨슈머의 토픽 할당을 카프카 내부적으로 구분하기 위해 사용하는 id 
		  (client id 에 uuid 같은거 사용함)
	- HOST
		- 컨슈머가 동작하는 host 명
		- 카프카에 붙은 컨슈머의 호스트명 또는 ip 를 알 수 있음
	- CLIENT-ID
		- 컨슈머에 할당된 id
## kafka-verifiable-producer
- 간단한 네트워크 통신 테스트 할 때 유용
```shell
$ kafka-verifiable-producer --bootstrap-server localhost:9092 \ <- 통신 하고자 하는 호스트와 포트
> --max-messages 10 \ 프로듀서로 보내는 데이터 갯수 지정. (-1 은 종료될 때 까지)
> --topic verify-test <- 데이터를 받을 대상 토픽
{"timestamp":1756736424105,"name":"startup_complete"} <- 최초 실행 시점
[2025-09-01 14:20:24,178] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 1 : {verify-test=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
{"timestamp":1756736424299,"name":"producer_send_success","key":null,"value":"0","topic":"verify-test","partition":0,"offset":0}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"1","topic":"verify-test","partition":0,"offset":1}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"2","topic":"verify-test","partition":0,"offset":2}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"3","topic":"verify-test","partition":0,"offset":3}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"4","topic":"verify-test","partition":0,"offset":4}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"5","topic":"verify-test","partition":0,"offset":5}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"6","topic":"verify-test","partition":0,"offset":6}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"7","topic":"verify-test","partition":0,"offset":7}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"8","topic":"verify-test","partition":0,"offset":8}
{"timestamp":1756736424300,"name":"producer_send_success","key":null,"value":"9","topic":"verify-test","partition":0,"offset":9}
{"timestamp":1756736424303,"name":"shutdown_complete"}
{"timestamp":1756736424303,"name":"tool_data","sent":10,"acked":10,"target_throughput":-1,"avg_throughput":50.505050505050505}
```
- 전송된 데이터는 kafka-verifiable-consumer 로 확인 가능
![[스크린샷 2025-09-01 23.24.07.png]]
## kafka-verifiable-consumer
```shell
$ kafka-verifiable-consumer --bootstrap-server localhost:9092 \
  --topic verify-test \ <- 데이터를 가져오고자 하는 토픽
  --group-id test-group <- 그룹 지정
```
결과
- 컨슈머 실행
	- ![[스크린샷 2025-09-01 23.28.52.png]]
- 프로듀서 실행
	- ![[스크린샷 2025-09-01 23.29.26.png]]
## kafka-delete-records
- 적재된 토픽을 지움
	- 가장 오래된 데이터 부터 특정 시점의 오프셋까지 삭제 가능
```shell
$ vi delete-topic-target.json
{"partitions": [{"topic": "test", "partition": 0, "offset": 50}], "version":1 }
$ bin/kafka-delete-records --bootstrap-server localhost:9092 \
  --offset-json-file delete-topic-target.json
```
- kafka 는 토픽을 즉시 지우지 않고 삭제 마커를 남김
	- 그 파일이름은 **delete-topic.json** 파일
	- 경로는 보통 `/var/lib/kafka/data/<topic-name>/delete-topic.json` 에 위치함
	- 브로커가 GC 돌면서 수거함
